{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "id": "B1sxEcEcB5u1",
        "outputId": "335cb6b7-6aab-4821-cc71-a1913f04924e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.24.3\n",
            "  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja==1.11.1.1\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging==23.1\n",
            "  Downloading packaging-23.1-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ninja, packaging, numpy\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-stubs 2.0.3.230814 requires numpy>=1.25.0; python_version >= \"3.9\", but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ninja-1.11.1.1 numpy-1.24.3 packaging-23.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "612c1525aad04e33a4b634d36ed1e0e5"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install numpy==1.24.3 ninja==1.11.1.1 packaging==23.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ilxt3z0ACLiQ",
        "outputId": "99fda977-fe3f-4f17-a9cd-68afdb656a2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.17.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.24.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3PvKk_CxDG8j",
        "outputId": "1873d577-a9c6-4f62-c7ba-c13825c948ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.35.2\n",
            "  Downloading transformers-4.35.2-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-2.19.0-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hydra-core==1.3.2\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb==0.15.3\n",
            "  Downloading wandb-0.15.3-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai==1.6.1\n",
            "  Downloading openai-1.6.1-py3-none-any.whl (225 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.4/225.4 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate==0.21.0\n",
            "  Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensor-parallel==1.2.4\n",
            "  Downloading tensor_parallel-1.2.4-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2) (2.31.0)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers==4.35.2)\n",
            "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2) (4.66.2)\n",
            "Collecting omegaconf<2.4,>=2.2 (from hydra-core==1.3.2)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.9.* (from hydra-core==1.3.2)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.3) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb==0.15.3)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.3) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb==0.15.3)\n",
            "  Downloading sentry_sdk-1.45.0-py2.py3-none-any.whl (267 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.1/267.1 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb==0.15.3)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting pathtools (from wandb==0.15.3)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb==0.15.3)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.3) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.3) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.15.3) (3.20.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.6.1) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.6.1) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai==1.6.1)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.6.1) (2.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.6.1) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai==1.6.1) (4.11.0)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0) (2.2.1+cu121)\n",
            "Collecting peft>=0.3.0 (from tensor-parallel==1.2.4)\n",
            "  Downloading peft-0.10.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers==4.35.2)\n",
            "  Downloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.6.1) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.6.1) (1.2.1)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb==0.15.3) (1.16.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb==0.15.3)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.6.1) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai==1.6.1)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.6.1)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.6.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai==1.6.1) (2.18.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.35.2) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.35.2) (2.0.7)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.21.0) (12.4.127)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb==0.15.3)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.21.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.21.0) (1.3.0)\n",
            "Building wheels for collected packages: antlr4-python3-runtime, pathtools\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=f8218fc390b09a787dc319343f0dc9c0a907bfe4a5c83b7e71ab5dba8505af78\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=f285b4f7712d3176153a02144be4ea5467dd59d22a2d24b80ca785d7186e4ff0\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built antlr4-python3-runtime pathtools\n",
            "Installing collected packages: pathtools, antlr4-python3-runtime, xxhash, smmap, setproctitle, sentry-sdk, omegaconf, h11, docker-pycreds, dill, multiprocess, hydra-core, huggingface-hub, httpcore, gitdb, tokenizers, httpx, GitPython, wandb, transformers, openai, datasets, accelerate, peft, tensor-parallel\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.40.0\n",
            "    Uninstalling transformers-4.40.0:\n",
            "      Successfully uninstalled transformers-4.40.0\n",
            "Successfully installed GitPython-3.1.43 accelerate-0.21.0 antlr4-python3-runtime-4.9.3 datasets-2.19.0 dill-0.3.8 docker-pycreds-0.4.0 gitdb-4.0.11 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 huggingface-hub-0.22.2 hydra-core-1.3.2 multiprocess-0.70.16 omegaconf-2.3.0 openai-1.6.1 pathtools-0.1.2 peft-0.10.0 sentry-sdk-1.45.0 setproctitle-1.3.3 smmap-5.0.1 tensor-parallel-1.2.4 tokenizers-0.15.2 transformers-4.35.2 wandb-0.15.3 xxhash-3.4.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "9cc1d3cf574241ecbb620858bade2846"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install transformers==4.35.2 datasets hydra-core==1.3.2 wandb==0.15.3 openai==1.6.1 accelerate==0.21.0 tensor-parallel==1.2.4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfoKTRcIC-PI",
        "outputId": "eed814e4-c8d1-42bd-974a-d4a2c9c4b6bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flash-attn==1.0.4\n",
            "  Downloading flash_attn-1.0.4.tar.gz (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from flash-attn==1.0.4) (2.2.1+cu121)\n",
            "Collecting einops (from flash-attn==1.0.4)\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from flash-attn==1.0.4) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==1.0.4) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==1.0.4) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==1.0.4) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==1.0.4) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==1.0.4) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==1.0.4) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==1.0.4) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==1.0.4) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==1.0.4) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==1.0.4) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==1.0.4) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==1.0.4) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==1.0.4) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==1.0.4) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==1.0.4) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==1.0.4) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==1.0.4) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->flash-attn==1.0.4) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->flash-attn==1.0.4) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->flash-attn==1.0.4) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->flash-attn==1.0.4) (1.3.0)\n",
            "Building wheels for collected packages: flash-attn\n"
          ]
        }
      ],
      "source": [
        "!pip install flash-attn==1.0.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOv2yXAMGWtR",
        "outputId": "1c6fdea9-452e-4035-df80-e9a2e4f0642b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "2024-04-01 16:32:14.915666: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-01 16:32:14.915737: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-01 16:32:14.917102: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-01 16:32:16.094180: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "Making experiment directory /data/models/trial1_colab\n",
            "no FSDP port specified; using open port for FSDP: 41639\n",
            "seed: 1\n",
            "exp_name: trial1_colab\n",
            "datasets:\n",
            "- hh\n",
            "mode: train\n",
            "debug: false\n",
            "use_fsdp: true\n",
            "fsdp_port: 41639\n",
            "wandb:\n",
            "  enabled: true\n",
            "  entity: null\n",
            "  project: archangel\n",
            "cache_dir: /data/models\n",
            "local_run_dir: /data/models/trial1_colab\n",
            "do_first_eval: true\n",
            "minimum_log_interval_secs: 1.0\n",
            "intermediate_checkpoints: false\n",
            "trainer: BasicTrainer\n",
            "lr: 5.0e-07\n",
            "n_epochs: 1\n",
            "n_examples: null\n",
            "optimizer: RMSprop\n",
            "warmup_steps: 150\n",
            "eval_every: 20000\n",
            "n_samples: 128\n",
            "samples_dir: samples/\n",
            "n_eval_examples: 512\n",
            "saved_policy: /data/models/trial1_colab/LATEST/policy.pt\n",
            "top_p: 0.95\n",
            "human_prefix: '\n",
            "\n",
            "  <|user|>\n",
            "\n",
            "  '\n",
            "assistant_prefix: '\n",
            "\n",
            "  <|assistant|>\n",
            "\n",
            "  '\n",
            "human_suffix: ''\n",
            "assistant_suffix: ''\n",
            "frac_unique_desirable: 1.0\n",
            "frac_unique_undesirable: 1.0\n",
            "model:\n",
            "  name_or_path: EleutherAI/pythia-1.4b\n",
            "  tokenizer_name_or_path: null\n",
            "  load_from: null\n",
            "  block_name: GPTNeoXLayer\n",
            "  policy_dtype: bfloat16\n",
            "  fsdp_policy_mp: null\n",
            "  reference_dtype: bfloat16\n",
            "  max_grad_norm: 10.0\n",
            "  v_head_max_grad_norm: 0.1\n",
            "  max_length: 2048\n",
            "  max_prompt_length: 1024\n",
            "  activation_checkpointing: true\n",
            "  batch_size: 16\n",
            "  gradient_accumulation_steps: 1\n",
            "  eval_batch_size: 8\n",
            "  use_flash_attention: false\n",
            "loss:\n",
            "  name: sft\n",
            "  trainer: SFTTrainer\n",
            "  dataloader: SFTDataLoader\n",
            "  use_reference_model: false\n",
            "\n",
            "================================================================================\n",
            "Writing to 2587113e2ca2:/data/models/trial1_colab\n",
            "================================================================================\n",
            "building policy\n",
            "Loading tokenizer EleutherAI/pythia-1.4b\n",
            "0 special tokens added\n",
            "Loading HH dataset (train split) from Huggingface...\n",
            "Processing HH: 100% 160800/160800 [00:21<00:00, 7430.25it/s]\n",
            "Loading HH dataset (test split) from Huggingface...\n",
            "Processing HH: 100% 8552/8552 [00:01<00:00, 5725.26it/s]\n",
            "starting 1 processes for FSDP training\n",
            "setting RLIMIT_NOFILE soft limit to 1048576 from 1048576\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "2024-04-01 16:33:08.729929: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-01 16:33:08.729985: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-01 16:33:08.731151: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-01 16:33:09.886920: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "0 initializing distributed\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mninadchaphekar\u001b[0m (\u001b[33mninad30\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.16.5 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/data/models/wandb/run-20240401_163315-ka3ytnnh\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtrial1_colab\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ninad30/archangel\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ninad30/archangel/runs/ka3ytnnh\u001b[0m\n",
            "Creating trainer on process 0 with world size 1\n",
            "Finished generating 512 examples on test split\n",
            "Loaded 64 eval batches of size 8\n",
            "Sharding models...\n",
            "Attempting to enable activation checkpointing...\n",
            "Applying activation checkpointing wrapper to policy...\n",
            "FSDP activation checkpointing enabled!\n",
            "Loaded model on rank 0\n",
            "Using RMSprop optimizer with learning rate 5e-07\n",
            "Running evaluation after 0 train examples\n",
            "Computing eval metrics: 100% 64/64 [06:11<00:00,  5.80s/it]\n",
            "eval after 0: {'logps_eval/chosen': '-168.68', 'loss/eval': '168.68'}\n",
            "train stats after 16 examples: {'logps_train/chosen': '-148.45', 'loss/train': '148.45', 'grad_norm': '864', 'examples_per_second': '0.70076', 'counters/examples': 16, 'counters/updates': 1}\n",
            "train stats after 32 examples: {'logps_train/chosen': '-204.28', 'loss/train': '204.28', 'grad_norm': '884', 'examples_per_second': '0.44772', 'counters/examples': 32, 'counters/updates': 2}\n",
            "Error executing job with overrides: ['loss=sft', 'model=pythia1-4b', 'datasets=[hh]', 'exp_name=trial1_colab', 'mode=train', '++cache_dir=/data/models']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/HALOs/train.py\", line 224, in main\n",
            "    mp.spawn(worker_main, nprocs=world_size, args=(world_size, config, tokenizer, train_iterator, eval_iterator, policy, reference_model), join=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/spawn.py\", line 241, in spawn\n",
            "    return start_processes(fn, args, nprocs, join, daemon, start_method=\"spawn\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/spawn.py\", line 197, in start_processes\n",
            "    while not context.join():\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/spawn.py\", line 158, in join\n",
            "    raise ProcessRaisedException(msg, error_index, failed_process.pid)\n",
            "torch.multiprocessing.spawn.ProcessRaisedException: \n",
            "\n",
            "-- Process 0 terminated with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/spawn.py\", line 68, in _wrap\n",
            "    fn(i, *args)\n",
            "  File \"/content/HALOs/train.py\", line 81, in worker_main\n",
            "    trainer.train()\n",
            "  File \"/content/HALOs/trainers.py\", line 396, in train\n",
            "    loss, metrics = self.get_batch_metrics(local_microbatch)\n",
            "  File \"/content/HALOs/trainers.py\", line 541, in get_batch_metrics\n",
            "    policy_chosen_logps = get_batch_logps(policy_chosen_logits, batch['target_labels'], average_log_prob=False)\n",
            "  File \"/content/HALOs/utils.py\", line 108, in get_batch_logps\n",
            "    distribution_logps = logits.log_softmax(-1)\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.19 GiB. GPU 0 has a total capacity of 14.75 GiB of which 1.08 GiB is free. Process 512293 has 13.66 GiB memory in use. Of the allocated memory 9.03 GiB is allocated by PyTorch, and 4.19 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "\n",
            "\n",
            "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n"
          ]
        }
      ],
      "source": [
        "!python /content/HALOs/train.py loss=sft model=pythia1-4b datasets=[hh] exp_name=trial1_colab mode=train ++cache_dir=/data/models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login(key=\"1330875d63b22aaf4bd58e3eb37e63b493347bb6\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h62n3-fHeeYi",
        "outputId": "e2c94bdb-40dc-4e81-f1d6-8ca1c3b2d629"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change variables in config files to reduce batch size etc"
      ],
      "metadata": {
        "id": "mcBUcf8hx8O2"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0q9aVmfByKgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9aAUcJPHyKdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zmHspt-NyKbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pST1VEZPyKYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/HALOs/train.py loss=sft model=pythia1-4b datasets=[hh] exp_name=trial1_colab mode=train ++cache_dir=/data/models\n",
        "\n",
        "# Maybe prompt size is too big to calculate the attention"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdUCTS2EepFx",
        "outputId": "b7655e6b-38f3-4f6b-90d5-0ad9e388661c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "2024-04-01 16:46:06.852117: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-01 16:46:06.852183: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-01 16:46:06.854179: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-01 16:46:08.218952: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "Making experiment directory /data/models/trial1_colab\n",
            "no FSDP port specified; using open port for FSDP: 42349\n",
            "seed: 1\n",
            "exp_name: trial1_colab\n",
            "datasets:\n",
            "- hh\n",
            "mode: train\n",
            "debug: false\n",
            "use_fsdp: true\n",
            "fsdp_port: 42349\n",
            "wandb:\n",
            "  enabled: true\n",
            "  entity: null\n",
            "  project: archangel\n",
            "cache_dir: /data/models\n",
            "local_run_dir: /data/models/trial1_colab\n",
            "do_first_eval: true\n",
            "minimum_log_interval_secs: 1.0\n",
            "intermediate_checkpoints: false\n",
            "trainer: BasicTrainer\n",
            "lr: 5.0e-07\n",
            "n_epochs: 1\n",
            "n_examples: null\n",
            "optimizer: RMSprop\n",
            "warmup_steps: 150\n",
            "eval_every: 20000\n",
            "n_samples: 32\n",
            "samples_dir: samples/\n",
            "n_eval_examples: 128\n",
            "saved_policy: /data/models/trial1_colab/LATEST/policy.pt\n",
            "top_p: 0.95\n",
            "human_prefix: '\n",
            "\n",
            "  <|user|>\n",
            "\n",
            "  '\n",
            "assistant_prefix: '\n",
            "\n",
            "  <|assistant|>\n",
            "\n",
            "  '\n",
            "human_suffix: ''\n",
            "assistant_suffix: ''\n",
            "frac_unique_desirable: 1.0\n",
            "frac_unique_undesirable: 1.0\n",
            "model:\n",
            "  name_or_path: EleutherAI/pythia-1.4b\n",
            "  tokenizer_name_or_path: null\n",
            "  load_from: null\n",
            "  block_name: GPTNeoXLayer\n",
            "  policy_dtype: bfloat16\n",
            "  fsdp_policy_mp: null\n",
            "  reference_dtype: bfloat16\n",
            "  max_grad_norm: 10.0\n",
            "  v_head_max_grad_norm: 0.1\n",
            "  max_length: 2048\n",
            "  max_prompt_length: 1024\n",
            "  activation_checkpointing: true\n",
            "  batch_size: 8\n",
            "  gradient_accumulation_steps: 1\n",
            "  eval_batch_size: 4\n",
            "  use_flash_attention: false\n",
            "loss:\n",
            "  name: sft\n",
            "  trainer: SFTTrainer\n",
            "  dataloader: SFTDataLoader\n",
            "  use_reference_model: false\n",
            "\n",
            "================================================================================\n",
            "Writing to 2587113e2ca2:/data/models/trial1_colab\n",
            "================================================================================\n",
            "building policy\n",
            "Loading tokenizer EleutherAI/pythia-1.4b\n",
            "0 special tokens added\n",
            "Loading HH dataset (train split) from Huggingface...\n",
            "Processing HH: 100% 160800/160800 [00:23<00:00, 6878.17it/s]\n",
            "Loading HH dataset (test split) from Huggingface...\n",
            "Processing HH: 100% 8552/8552 [00:01<00:00, 5616.92it/s]\n",
            "starting 1 processes for FSDP training\n",
            "setting RLIMIT_NOFILE soft limit to 1048576 from 1048576\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "2024-04-01 16:47:01.939608: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-01 16:47:01.939664: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-01 16:47:01.940891: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-01 16:47:03.095228: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "0 initializing distributed\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mninadchaphekar\u001b[0m (\u001b[33mninad30\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.16.5 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/data/models/wandb/run-20240401_164708-kjo3huy3\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtrial1_colab\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ninad30/archangel\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ninad30/archangel/runs/kjo3huy3\u001b[0m\n",
            "Creating trainer on process 0 with world size 1\n",
            "Finished generating 128 examples on test split\n",
            "Loaded 32 eval batches of size 4\n",
            "Sharding models...\n",
            "Attempting to enable activation checkpointing...\n",
            "Applying activation checkpointing wrapper to policy...\n",
            "FSDP activation checkpointing enabled!\n",
            "Loaded model on rank 0\n",
            "Using RMSprop optimizer with learning rate 5e-07\n",
            "Running evaluation after 0 train examples\n",
            "Computing eval metrics: 100% 32/32 [01:05<00:00,  2.04s/it]\n",
            "eval after 0: {'logps_eval/chosen': '-191.41', 'loss/eval': '191.41'}\n",
            "train stats after 8 examples: {'logps_train/chosen': '-116.09', 'loss/train': '116.09', 'grad_norm': '936', 'examples_per_second': '0.72194', 'counters/examples': 8, 'counters/updates': 1}\n",
            "train stats after 16 examples: {'logps_train/chosen': '-180.62', 'loss/train': '180.62', 'grad_norm': '1064', 'examples_per_second': '0.81597', 'counters/examples': 16, 'counters/updates': 2}\n",
            "train stats after 24 examples: {'logps_train/chosen': '-250.44', 'loss/train': '250.44', 'grad_norm': '1128', 'examples_per_second': '0.43372', 'counters/examples': 24, 'counters/updates': 3}\n",
            "train stats after 32 examples: {'logps_train/chosen': '-158.09', 'loss/train': '158.09', 'grad_norm': '928', 'examples_per_second': '0.54287', 'counters/examples': 32, 'counters/updates': 4}\n",
            "train stats after 40 examples: {'logps_train/chosen': '-177.44', 'loss/train': '177.44', 'grad_norm': '1020', 'examples_per_second': '0.76674', 'counters/examples': 40, 'counters/updates': 5}\n",
            "train stats after 48 examples: {'logps_train/chosen': '-120.33', 'loss/train': '120.33', 'grad_norm': '820', 'examples_per_second': '0.28789', 'counters/examples': 48, 'counters/updates': 6}\n",
            "train stats after 56 examples: {'logps_train/chosen': '-207.84', 'loss/train': '207.84', 'grad_norm': '1056', 'examples_per_second': '0.68019', 'counters/examples': 56, 'counters/updates': 7}\n",
            "train stats after 64 examples: {'logps_train/chosen': '-226.97', 'loss/train': '226.97', 'grad_norm': '1080', 'examples_per_second': '0.64221', 'counters/examples': 64, 'counters/updates': 8}\n",
            "train stats after 72 examples: {'logps_train/chosen': '-129.66', 'loss/train': '129.66', 'grad_norm': '904', 'examples_per_second': '0.56215', 'counters/examples': 72, 'counters/updates': 9}\n",
            "train stats after 80 examples: {'logps_train/chosen': '-108.36', 'loss/train': '108.36', 'grad_norm': '812', 'examples_per_second': '0.69435', 'counters/examples': 80, 'counters/updates': 10}\n",
            "train stats after 88 examples: {'logps_train/chosen': '-266.38', 'loss/train': '266.38', 'grad_norm': '1168', 'examples_per_second': '0.50351', 'counters/examples': 88, 'counters/updates': 11}\n",
            "train stats after 96 examples: {'logps_train/chosen': '-96.391', 'loss/train': '96.391', 'grad_norm': '788', 'examples_per_second': '0.60876', 'counters/examples': 96, 'counters/updates': 12}\n",
            "train stats after 104 examples: {'logps_train/chosen': '-98.141', 'loss/train': '98.141', 'grad_norm': '820', 'examples_per_second': '0.57709', 'counters/examples': 104, 'counters/updates': 13}\n",
            "train stats after 112 examples: {'logps_train/chosen': '-119.88', 'loss/train': '119.88', 'grad_norm': '916', 'examples_per_second': '0.80416', 'counters/examples': 112, 'counters/updates': 14}\n",
            "train stats after 120 examples: {'logps_train/chosen': '-153.55', 'loss/train': '153.55', 'grad_norm': '896', 'examples_per_second': '0.75859', 'counters/examples': 120, 'counters/updates': 15}\n",
            "train stats after 128 examples: {'logps_train/chosen': '-139.53', 'loss/train': '139.53', 'grad_norm': '976', 'examples_per_second': '0.15898', 'counters/examples': 128, 'counters/updates': 16}\n",
            "train stats after 136 examples: {'logps_train/chosen': '-140.34', 'loss/train': '140.34', 'grad_norm': '880', 'examples_per_second': '0.50919', 'counters/examples': 136, 'counters/updates': 17}\n",
            "train stats after 144 examples: {'logps_train/chosen': '-175.5', 'loss/train': '175.5', 'grad_norm': '1072', 'examples_per_second': '0.50913', 'counters/examples': 144, 'counters/updates': 18}\n",
            "train stats after 152 examples: {'logps_train/chosen': '-231.66', 'loss/train': '231.66', 'grad_norm': '1176', 'examples_per_second': '0.63086', 'counters/examples': 152, 'counters/updates': 19}\n",
            "train stats after 160 examples: {'logps_train/chosen': '-133.34', 'loss/train': '133.34', 'grad_norm': '920', 'examples_per_second': '0.71539', 'counters/examples': 160, 'counters/updates': 20}\n",
            "train stats after 168 examples: {'logps_train/chosen': '-114.83', 'loss/train': '114.83', 'grad_norm': '840', 'examples_per_second': '0.27499', 'counters/examples': 168, 'counters/updates': 21}\n",
            "train stats after 176 examples: {'logps_train/chosen': '-119.25', 'loss/train': '119.25', 'grad_norm': '852', 'examples_per_second': '0.53192', 'counters/examples': 176, 'counters/updates': 22}\n",
            "train stats after 184 examples: {'logps_train/chosen': '-189.97', 'loss/train': '189.97', 'grad_norm': '1032', 'examples_per_second': '0.36419', 'counters/examples': 184, 'counters/updates': 23}\n",
            "train stats after 192 examples: {'logps_train/chosen': '-253.19', 'loss/train': '253.19', 'grad_norm': '1128', 'examples_per_second': '0.46567', 'counters/examples': 192, 'counters/updates': 24}\n",
            "train stats after 200 examples: {'logps_train/chosen': '-183.39', 'loss/train': '183.39', 'grad_norm': '1004', 'examples_per_second': '0.36122', 'counters/examples': 200, 'counters/updates': 25}\n",
            "train stats after 208 examples: {'logps_train/chosen': '-161.78', 'loss/train': '161.78', 'grad_norm': '992', 'examples_per_second': '0.36638', 'counters/examples': 208, 'counters/updates': 26}\n",
            "train stats after 216 examples: {'logps_train/chosen': '-165.23', 'loss/train': '165.23', 'grad_norm': '984', 'examples_per_second': '0.53377', 'counters/examples': 216, 'counters/updates': 27}\n",
            "train stats after 224 examples: {'logps_train/chosen': '-159.31', 'loss/train': '159.31', 'grad_norm': '1072', 'examples_per_second': '0.36359', 'counters/examples': 224, 'counters/updates': 28}\n",
            "train stats after 232 examples: {'logps_train/chosen': '-154.69', 'loss/train': '154.69', 'grad_norm': '936', 'examples_per_second': '0.59216', 'counters/examples': 232, 'counters/updates': 29}\n",
            "train stats after 240 examples: {'logps_train/chosen': '-162.12', 'loss/train': '162.12', 'grad_norm': '984', 'examples_per_second': '0.36486', 'counters/examples': 240, 'counters/updates': 30}\n",
            "train stats after 248 examples: {'logps_train/chosen': '-139.16', 'loss/train': '139.16', 'grad_norm': '1056', 'examples_per_second': '0.46961', 'counters/examples': 248, 'counters/updates': 31}\n",
            "train stats after 256 examples: {'logps_train/chosen': '-175.84', 'loss/train': '175.84', 'grad_norm': '908', 'examples_per_second': '0.56146', 'counters/examples': 256, 'counters/updates': 32}\n",
            "train stats after 264 examples: {'logps_train/chosen': '-218.44', 'loss/train': '218.44', 'grad_norm': '1064', 'examples_per_second': '0.54582', 'counters/examples': 264, 'counters/updates': 33}\n",
            "train stats after 272 examples: {'logps_train/chosen': '-213.41', 'loss/train': '213.41', 'grad_norm': '1024', 'examples_per_second': '0.28745', 'counters/examples': 272, 'counters/updates': 34}\n",
            "train stats after 280 examples: {'logps_train/chosen': '-132.59', 'loss/train': '132.59', 'grad_norm': '856', 'examples_per_second': '0.3885', 'counters/examples': 280, 'counters/updates': 35}\n",
            "train stats after 288 examples: {'logps_train/chosen': '-93.172', 'loss/train': '93.172', 'grad_norm': '772', 'examples_per_second': '0.41205', 'counters/examples': 288, 'counters/updates': 36}\n",
            "train stats after 296 examples: {'logps_train/chosen': '-209.97', 'loss/train': '209.97', 'grad_norm': '1024', 'examples_per_second': '0.36235', 'counters/examples': 296, 'counters/updates': 37}\n",
            "train stats after 304 examples: {'logps_train/chosen': '-141.56', 'loss/train': '141.56', 'grad_norm': '888', 'examples_per_second': '0.50686', 'counters/examples': 304, 'counters/updates': 38}\n",
            "train stats after 312 examples: {'logps_train/chosen': '-300.62', 'loss/train': '300.62', 'grad_norm': '1296', 'examples_per_second': '0.43192', 'counters/examples': 312, 'counters/updates': 39}\n",
            "train stats after 320 examples: {'logps_train/chosen': '-115.47', 'loss/train': '115.47', 'grad_norm': '808', 'examples_per_second': '0.52666', 'counters/examples': 320, 'counters/updates': 40}\n",
            "train stats after 328 examples: {'logps_train/chosen': '-171.14', 'loss/train': '171.14', 'grad_norm': '908', 'examples_per_second': '0.53412', 'counters/examples': 328, 'counters/updates': 41}\n",
            "train stats after 336 examples: {'logps_train/chosen': '-154.12', 'loss/train': '154.12', 'grad_norm': '924', 'examples_per_second': '0.69609', 'counters/examples': 336, 'counters/updates': 42}\n",
            "train stats after 344 examples: {'logps_train/chosen': '-130.53', 'loss/train': '130.53', 'grad_norm': '900', 'examples_per_second': '0.63023', 'counters/examples': 344, 'counters/updates': 43}\n",
            "train stats after 352 examples: {'logps_train/chosen': '-186.41', 'loss/train': '186.41', 'grad_norm': '1032', 'examples_per_second': '0.49458', 'counters/examples': 352, 'counters/updates': 44}\n",
            "train stats after 360 examples: {'logps_train/chosen': '-114.38', 'loss/train': '114.38', 'grad_norm': '820', 'examples_per_second': '0.90875', 'counters/examples': 360, 'counters/updates': 45}\n",
            "train stats after 368 examples: {'logps_train/chosen': '-179.08', 'loss/train': '179.08', 'grad_norm': '1128', 'examples_per_second': '0.2419', 'counters/examples': 368, 'counters/updates': 46}\n",
            "train stats after 376 examples: {'logps_train/chosen': '-166.44', 'loss/train': '166.44', 'grad_norm': '1168', 'examples_per_second': '0.46005', 'counters/examples': 376, 'counters/updates': 47}\n",
            "train stats after 384 examples: {'logps_train/chosen': '-102.53', 'loss/train': '102.53', 'grad_norm': '812', 'examples_per_second': '0.37805', 'counters/examples': 384, 'counters/updates': 48}\n",
            "train stats after 392 examples: {'logps_train/chosen': '-138.84', 'loss/train': '138.84', 'grad_norm': '972', 'examples_per_second': '0.38236', 'counters/examples': 392, 'counters/updates': 49}\n",
            "train stats after 400 examples: {'logps_train/chosen': '-195.94', 'loss/train': '195.94', 'grad_norm': '1016', 'examples_per_second': '0.33238', 'counters/examples': 400, 'counters/updates': 50}\n",
            "train stats after 408 examples: {'logps_train/chosen': '-101.67', 'loss/train': '101.67', 'grad_norm': '764', 'examples_per_second': '0.63144', 'counters/examples': 408, 'counters/updates': 51}\n",
            "train stats after 416 examples: {'logps_train/chosen': '-145.81', 'loss/train': '145.81', 'grad_norm': '916', 'examples_per_second': '0.38671', 'counters/examples': 416, 'counters/updates': 52}\n",
            "train stats after 424 examples: {'logps_train/chosen': '-189.14', 'loss/train': '189.14', 'grad_norm': '992', 'examples_per_second': '0.50262', 'counters/examples': 424, 'counters/updates': 53}\n",
            "train stats after 432 examples: {'logps_train/chosen': '-220.41', 'loss/train': '220.41', 'grad_norm': '1128', 'examples_per_second': '0.41429', 'counters/examples': 432, 'counters/updates': 54}\n",
            "train stats after 440 examples: {'logps_train/chosen': '-167.33', 'loss/train': '167.33', 'grad_norm': '1020', 'examples_per_second': '0.40097', 'counters/examples': 440, 'counters/updates': 55}\n",
            "train stats after 448 examples: {'logps_train/chosen': '-214.39', 'loss/train': '214.39', 'grad_norm': '1128', 'examples_per_second': '0.43994', 'counters/examples': 448, 'counters/updates': 56}\n",
            "train stats after 456 examples: {'logps_train/chosen': '-191.53', 'loss/train': '191.53', 'grad_norm': '1080', 'examples_per_second': '0.51102', 'counters/examples': 456, 'counters/updates': 57}\n",
            "train stats after 464 examples: {'logps_train/chosen': '-121.12', 'loss/train': '121.12', 'grad_norm': '812', 'examples_per_second': '0.56893', 'counters/examples': 464, 'counters/updates': 58}\n",
            "train stats after 472 examples: {'logps_train/chosen': '-134.88', 'loss/train': '134.88', 'grad_norm': '908', 'examples_per_second': '0.50592', 'counters/examples': 472, 'counters/updates': 59}\n",
            "train stats after 480 examples: {'logps_train/chosen': '-98.156', 'loss/train': '98.156', 'grad_norm': '800', 'examples_per_second': '0.74087', 'counters/examples': 480, 'counters/updates': 60}\n",
            "train stats after 488 examples: {'logps_train/chosen': '-126.34', 'loss/train': '126.34', 'grad_norm': '968', 'examples_per_second': '0.35268', 'counters/examples': 488, 'counters/updates': 61}\n",
            "train stats after 496 examples: {'logps_train/chosen': '-90.156', 'loss/train': '90.156', 'grad_norm': '772', 'examples_per_second': '1.4008', 'counters/examples': 496, 'counters/updates': 62}\n",
            "train stats after 504 examples: {'logps_train/chosen': '-176.72', 'loss/train': '176.72', 'grad_norm': '1032', 'examples_per_second': '0.50185', 'counters/examples': 504, 'counters/updates': 63}\n",
            "train stats after 512 examples: {'logps_train/chosen': '-102.84', 'loss/train': '102.84', 'grad_norm': '860', 'examples_per_second': '0.64598', 'counters/examples': 512, 'counters/updates': 64}\n",
            "train stats after 520 examples: {'logps_train/chosen': '-211.38', 'loss/train': '211.38', 'grad_norm': '1064', 'examples_per_second': '0.39992', 'counters/examples': 520, 'counters/updates': 65}\n",
            "train stats after 528 examples: {'logps_train/chosen': '-159.28', 'loss/train': '159.28', 'grad_norm': '956', 'examples_per_second': '0.37552', 'counters/examples': 528, 'counters/updates': 66}\n",
            "train stats after 536 examples: {'logps_train/chosen': '-131.44', 'loss/train': '131.44', 'grad_norm': '928', 'examples_per_second': '0.61171', 'counters/examples': 536, 'counters/updates': 67}\n",
            "train stats after 544 examples: {'logps_train/chosen': '-132.38', 'loss/train': '132.38', 'grad_norm': '808', 'examples_per_second': '0.54702', 'counters/examples': 544, 'counters/updates': 68}\n",
            "train stats after 552 examples: {'logps_train/chosen': '-152.97', 'loss/train': '152.97', 'grad_norm': '1020', 'examples_per_second': '0.97864', 'counters/examples': 552, 'counters/updates': 69}\n",
            "train stats after 560 examples: {'logps_train/chosen': '-180.97', 'loss/train': '180.97', 'grad_norm': '928', 'examples_per_second': '0.38282', 'counters/examples': 560, 'counters/updates': 70}\n",
            "train stats after 568 examples: {'logps_train/chosen': '-135.72', 'loss/train': '135.72', 'grad_norm': '892', 'examples_per_second': '0.34671', 'counters/examples': 568, 'counters/updates': 71}\n",
            "train stats after 576 examples: {'logps_train/chosen': '-160.92', 'loss/train': '160.92', 'grad_norm': '1024', 'examples_per_second': '0.62029', 'counters/examples': 576, 'counters/updates': 72}\n",
            "train stats after 584 examples: {'logps_train/chosen': '-135.16', 'loss/train': '135.16', 'grad_norm': '868', 'examples_per_second': '0.38343', 'counters/examples': 584, 'counters/updates': 73}\n",
            "train stats after 592 examples: {'logps_train/chosen': '-134.73', 'loss/train': '134.73', 'grad_norm': '1072', 'examples_per_second': '0.50472', 'counters/examples': 592, 'counters/updates': 74}\n",
            "train stats after 600 examples: {'logps_train/chosen': '-133.92', 'loss/train': '133.92', 'grad_norm': '876', 'examples_per_second': '0.79492', 'counters/examples': 600, 'counters/updates': 75}\n",
            "train stats after 608 examples: {'logps_train/chosen': '-165.06', 'loss/train': '165.06', 'grad_norm': '964', 'examples_per_second': '0.24368', 'counters/examples': 608, 'counters/updates': 76}\n",
            "train stats after 616 examples: {'logps_train/chosen': '-146.19', 'loss/train': '146.19', 'grad_norm': '880', 'examples_per_second': '0.80694', 'counters/examples': 616, 'counters/updates': 77}\n",
            "train stats after 624 examples: {'logps_train/chosen': '-81.219', 'loss/train': '81.219', 'grad_norm': '820', 'examples_per_second': '0.36357', 'counters/examples': 624, 'counters/updates': 78}\n",
            "train stats after 632 examples: {'logps_train/chosen': '-157.91', 'loss/train': '157.91', 'grad_norm': '908', 'examples_per_second': '0.28949', 'counters/examples': 632, 'counters/updates': 79}\n",
            "train stats after 640 examples: {'logps_train/chosen': '-112.72', 'loss/train': '112.72', 'grad_norm': '1012', 'examples_per_second': '0.56894', 'counters/examples': 640, 'counters/updates': 80}\n",
            "train stats after 648 examples: {'logps_train/chosen': '-137.5', 'loss/train': '137.5', 'grad_norm': '904', 'examples_per_second': '0.3984', 'counters/examples': 648, 'counters/updates': 81}\n",
            "train stats after 656 examples: {'logps_train/chosen': '-130.5', 'loss/train': '130.5', 'grad_norm': '948', 'examples_per_second': '0.23186', 'counters/examples': 656, 'counters/updates': 82}\n",
            "train stats after 664 examples: {'logps_train/chosen': '-109.44', 'loss/train': '109.44', 'grad_norm': '764', 'examples_per_second': '0.84082', 'counters/examples': 664, 'counters/updates': 83}\n",
            "train stats after 672 examples: {'logps_train/chosen': '-166.88', 'loss/train': '166.88', 'grad_norm': '928', 'examples_per_second': '0.48192', 'counters/examples': 672, 'counters/updates': 84}\n",
            "train stats after 680 examples: {'logps_train/chosen': '-179.72', 'loss/train': '179.72', 'grad_norm': '1056', 'examples_per_second': '0.85147', 'counters/examples': 680, 'counters/updates': 85}\n",
            "train stats after 688 examples: {'logps_train/chosen': '-164.25', 'loss/train': '164.25', 'grad_norm': '932', 'examples_per_second': '0.40559', 'counters/examples': 688, 'counters/updates': 86}\n",
            "train stats after 696 examples: {'logps_train/chosen': '-140.38', 'loss/train': '140.38', 'grad_norm': '944', 'examples_per_second': '1.1502', 'counters/examples': 696, 'counters/updates': 87}\n",
            "train stats after 704 examples: {'logps_train/chosen': '-185.09', 'loss/train': '185.09', 'grad_norm': '1056', 'examples_per_second': '0.56805', 'counters/examples': 704, 'counters/updates': 88}\n",
            "train stats after 712 examples: {'logps_train/chosen': '-117.94', 'loss/train': '117.94', 'grad_norm': '848', 'examples_per_second': '0.45744', 'counters/examples': 712, 'counters/updates': 89}\n",
            "train stats after 720 examples: {'logps_train/chosen': '-161.72', 'loss/train': '161.72', 'grad_norm': '920', 'examples_per_second': '0.45641', 'counters/examples': 720, 'counters/updates': 90}\n",
            "train stats after 728 examples: {'logps_train/chosen': '-137.12', 'loss/train': '137.12', 'grad_norm': '860', 'examples_per_second': '0.29744', 'counters/examples': 728, 'counters/updates': 91}\n",
            "train stats after 736 examples: {'logps_train/chosen': '-129.47', 'loss/train': '129.47', 'grad_norm': '868', 'examples_per_second': '0.87381', 'counters/examples': 736, 'counters/updates': 92}\n",
            "train stats after 744 examples: {'logps_train/chosen': '-162.98', 'loss/train': '162.98', 'grad_norm': '896', 'examples_per_second': '0.53628', 'counters/examples': 744, 'counters/updates': 93}\n",
            "train stats after 752 examples: {'logps_train/chosen': '-95.594', 'loss/train': '95.594', 'grad_norm': '696', 'examples_per_second': '0.53167', 'counters/examples': 752, 'counters/updates': 94}\n",
            "train stats after 760 examples: {'logps_train/chosen': '-206.38', 'loss/train': '206.38', 'grad_norm': '984', 'examples_per_second': '0.30748', 'counters/examples': 760, 'counters/updates': 95}\n",
            "train stats after 768 examples: {'logps_train/chosen': '-273.81', 'loss/train': '273.81', 'grad_norm': '1256', 'examples_per_second': '0.27495', 'counters/examples': 768, 'counters/updates': 96}\n",
            "train stats after 776 examples: {'logps_train/chosen': '-193.25', 'loss/train': '193.25', 'grad_norm': '1032', 'examples_per_second': '0.594', 'counters/examples': 776, 'counters/updates': 97}\n",
            "train stats after 784 examples: {'logps_train/chosen': '-180.81', 'loss/train': '180.81', 'grad_norm': '988', 'examples_per_second': '0.54948', 'counters/examples': 784, 'counters/updates': 98}\n",
            "train stats after 792 examples: {'logps_train/chosen': '-164.48', 'loss/train': '164.48', 'grad_norm': '956', 'examples_per_second': '0.58508', 'counters/examples': 792, 'counters/updates': 99}\n",
            "train stats after 800 examples: {'logps_train/chosen': '-269.94', 'loss/train': '269.94', 'grad_norm': '1240', 'examples_per_second': '0.26279', 'counters/examples': 800, 'counters/updates': 100}\n",
            "train stats after 808 examples: {'logps_train/chosen': '-172.97', 'loss/train': '172.97', 'grad_norm': '892', 'examples_per_second': '0.87776', 'counters/examples': 808, 'counters/updates': 101}\n",
            "train stats after 816 examples: {'logps_train/chosen': '-161.5', 'loss/train': '161.5', 'grad_norm': '968', 'examples_per_second': '0.67316', 'counters/examples': 816, 'counters/updates': 102}\n",
            "train stats after 824 examples: {'logps_train/chosen': '-218.59', 'loss/train': '218.59', 'grad_norm': '1104', 'examples_per_second': '0.59124', 'counters/examples': 824, 'counters/updates': 103}\n",
            "train stats after 832 examples: {'logps_train/chosen': '-175.81', 'loss/train': '175.81', 'grad_norm': '932', 'examples_per_second': '0.43389', 'counters/examples': 832, 'counters/updates': 104}\n",
            "train stats after 840 examples: {'logps_train/chosen': '-76.562', 'loss/train': '76.562', 'grad_norm': '688', 'examples_per_second': '0.55878', 'counters/examples': 840, 'counters/updates': 105}\n",
            "train stats after 848 examples: {'logps_train/chosen': '-177.81', 'loss/train': '177.81', 'grad_norm': '980', 'examples_per_second': '0.3698', 'counters/examples': 848, 'counters/updates': 106}\n",
            "train stats after 856 examples: {'logps_train/chosen': '-182.14', 'loss/train': '182.14', 'grad_norm': '936', 'examples_per_second': '0.2351', 'counters/examples': 856, 'counters/updates': 107}\n",
            "train stats after 864 examples: {'logps_train/chosen': '-126.75', 'loss/train': '126.75', 'grad_norm': '840', 'examples_per_second': '0.43998', 'counters/examples': 864, 'counters/updates': 108}\n",
            "train stats after 872 examples: {'logps_train/chosen': '-230.31', 'loss/train': '230.31', 'grad_norm': '1056', 'examples_per_second': '0.35479', 'counters/examples': 872, 'counters/updates': 109}\n",
            "train stats after 880 examples: {'logps_train/chosen': '-92.328', 'loss/train': '92.328', 'grad_norm': '704', 'examples_per_second': '0.41601', 'counters/examples': 880, 'counters/updates': 110}\n",
            "train stats after 888 examples: {'logps_train/chosen': '-214.48', 'loss/train': '214.48', 'grad_norm': '992', 'examples_per_second': '0.42561', 'counters/examples': 888, 'counters/updates': 111}\n",
            "Error executing job with overrides: ['loss=sft', 'model=pythia1-4b', 'datasets=[hh]', 'exp_name=trial1_colab', 'mode=train', '++cache_dir=/data/models']\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/HALOs/train.py\", line 224, in main\n",
            "    mp.spawn(worker_main, nprocs=world_size, args=(world_size, config, tokenizer, train_iterator, eval_iterator, policy, reference_model), join=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/spawn.py\", line 241, in spawn\n",
            "    return start_processes(fn, args, nprocs, join, daemon, start_method=\"spawn\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/spawn.py\", line 197, in start_processes\n",
            "    while not context.join():\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/spawn.py\", line 158, in join\n",
            "    raise ProcessRaisedException(msg, error_index, failed_process.pid)\n",
            "torch.multiprocessing.spawn.ProcessRaisedException: \n",
            "\n",
            "-- Process 0 terminated with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/multiprocessing/spawn.py\", line 68, in _wrap\n",
            "    fn(i, *args)\n",
            "  File \"/content/HALOs/train.py\", line 81, in worker_main\n",
            "    trainer.train()\n",
            "  File \"/content/HALOs/trainers.py\", line 396, in train\n",
            "    loss, metrics = self.get_batch_metrics(local_microbatch)\n",
            "  File \"/content/HALOs/trainers.py\", line 540, in get_batch_metrics\n",
            "    policy_chosen_logits = self.policy(batch['target_combined_input_ids'], attention_mask=batch['target_combined_attention_mask'], use_cache=(not self.is_mistral)).logits.to(self.policy_dtype)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py\", line 849, in forward\n",
            "    output = self._fsdp_wrapped_module(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/gpt_neox/modeling_gpt_neox.py\", line 780, in forward\n",
            "    outputs = self.gpt_neox(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/gpt_neox/modeling_gpt_neox.py\", line 671, in forward\n",
            "    outputs = layer(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/fsdp/fully_sharded_data_parallel.py\", line 849, in forward\n",
            "    output = self._fsdp_wrapped_module(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/algorithms/_checkpoint/checkpoint_wrapper.py\", line 168, in forward\n",
            "    return self.checkpoint_fn(  # type: ignore[misc]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_compile.py\", line 24, in inner\n",
            "    return torch._dynamo.disable(fn, recursive)(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\", line 489, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/external_utils.py\", line 17, in inner\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py\", line 489, in checkpoint\n",
            "    ret = function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/gpt_neox/modeling_gpt_neox.py\", line 440, in forward\n",
            "    attention_layer_outputs = self.attention(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/gpt_neox/modeling_gpt_neox.py\", line 191, in forward\n",
            "    attn_output, attn_weights = self._attn(query, key, value, attention_mask, head_mask)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/gpt_neox/modeling_gpt_neox.py\", line 248, in _attn\n",
            "    attn_scores = torch.baddbmm(\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 924.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 739.06 MiB is free. Process 559441 has 14.02 GiB memory in use. Of the allocated memory 12.34 GiB is allocated by PyTorch, and 1.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "\n",
            "\n",
            "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ByAmuPnTjh10"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}